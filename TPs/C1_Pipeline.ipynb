{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hugging Face Transformers \n",
    "Adapt√© de : cours NLP dispens√© √† Stanforfd et Hugging Face (Cours NLP)\n",
    "\n",
    "Ce notebook pr√©sente la biblioth√®que Python Hugging Face Transformers et quelques mod√®les courants que vous pouvez utiliser pour en tirer parti. Elle est particuli√®rement utile pour utiliser ou affiner des mod√®les de transformateurs pr√©-entra√Æn√©s pour vos projets.\n",
    "\n",
    "Hugging Face fournit un acc√®s aux mod√®les (√† la fois le code qui les impl√©mente et leurs poids pr√©-entra√Æn√©s (checkpoints), y compris les derniers LLMs comme Llama3, DBRX, etc), aux tokenizers sp√©cifiques aux mod√®les, ainsi qu'aux pipelines pour les t√¢ches courantes de NLP, et aux ensembles de donn√©es et m√©triques dans un paquetage s√©par√© `datasets`. \n",
    "Il existe des impl√©mentations en PyTorch, Tensorflow et Flax (mais nous utiliserons ici les versions PyTorch !).\n",
    "\n",
    "Nous allons passer en revue quelques cas d'utilisation :\n",
    "* Partie 1: Que peuvent faire les tansformers: Quelques Pipelines (end-to-end)(pr√™t √† l'emploi - **off-the-shelf**) pour r√©aliser diff√©rentes t√¢ches\n",
    "* Partie 2 : Exploitation des transformers : vue d'ensemble des tokenizers et des mod√®les\n",
    "* Partie 3 : Finetuning - pour votre propre t√¢che. Nous utiliserons un exemple de classification de sentiments.\n",
    "\n",
    "Voici des ressources suppl√©mentaires introduisant la biblioth√®que qui ont √©t√© utilis√©es pour r√©aliser ce tutoriel :\n",
    "\n",
    "* [Hugging Face Docs] (https://huggingface.co/docs/transformers/index)\n",
    "  * Documentation claire\n",
    "  * Tutoriels, visites guid√©es et carnets d'exemples\n",
    "  * Liste des mod√®les disponibles\n",
    "* [Hugging Face Course](https://huggingface.co/course/) (Plusieurs langues) \n",
    "* [Hugging Face Examples](https://github.com/huggingface/transformers/tree/main/examples/pytorch) Vous pouvez trouver des structures de code tr√®s similaires pour des t√¢ches/mod√®les en aval tr√®s diff√©rents en utilisant Huggingface.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_UXAjutbMhoa"
   },
   "source": [
    "#  Partie I- Pipelines : que peuvent faire les *transformers* ?\n",
    "\n",
    "ü§ó  proposent plusieurs pipelines, des mod√®les pr√©-entrain√©es pour r√©aliser des t√¢ches sp√©cifiques: analyse de sentiment, r√©sum√©, quesion r√©ponse, NER, traduction.\n",
    "(https://huggingface.co/docs/transformers/main_classes/pipelines)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P3GIqRT-Mhoe"
   },
   "source": [
    "Installez la biblioth√®que ü§ó *Transformers* pour ex√©cuter ce *notebook*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KGUwAC1zMhoj"
   },
   "outputs": [],
   "source": [
    "!pip install transformers -q\n",
    "#!pip install transformers [sentencepiece] # pTransformers avec les d√©pendances pour SentencePiece.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tf-keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Les pipelines :\n",
    "L‚Äôoutil le plus basique de la biblioth√®que ü§ó Transformers est la fonction pipeline(). Elle relie un mod√®le avec ses √©tapes de pr√©-traitement et de post-traitement, permettant d‚Äôentrer n‚Äôimporte quel texte et d‚Äôobtenir une r√©ponse compr√©hensible :\n",
    "<img src=\"./images/pipline.jpg\"  style=\"width:550px;height:150px;\" >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ehB754vsO78P"
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5VmlNOR-OdIU"
   },
   "source": [
    "### 1 Exemple de pipeline : Analyse de sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ILYepD-3Mhom"
   },
   "outputs": [],
   "source": [
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "classifier(\"I've been waiting for a HuggingFace course my whole life.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©ation de la pipeline\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "# Inspection du mod√®le utilis√© par d√©faut\n",
    "print(\"Mod√®le utilis√© : par d√©faut\", classifier.model.name_or_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import webbrowser\n",
    "from transformers import pipeline\n",
    "\n",
    "model_name = pipeline(\"sentiment-analysis\").model.name_or_path\n",
    "webbrowser.open(f\"https://huggingface.co/{model_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uYmC3B-ZMhoo"
   },
   "outputs": [],
   "source": [
    "classifier = pipeline(\"sentiment-analysis\", model=\"tblard/tf-allocine\")\n",
    "classifier(\"J'ai attendu un cours d'HuggingFace toute ma vie.\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WSiD3eYEMhos"
   },
   "source": [
    "Int√©ressant ! On observe que le r√©sultat est n√©gatif l√† o√π pour la version en anglais le r√©sultat est positif."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On peut fournir plusieurs textes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6jo4BXTXMhou"
   },
   "outputs": [],
   "source": [
    "classifier(\n",
    "    [\"J'ai attendu un cours d'HuggingFace toute ma vie.\", \n",
    "     \"Je d√©teste tellement √ßa !\"]\n",
    ") # pour classifier plusieurs phrases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8LQ52fFqOrQa"
   },
   "source": [
    "#### Voici une liste non-exhaustive des pipelines disponibles :\n",
    "\n",
    "- feature-extraction (pour obtenir la repr√©sentation vectorielle d‚Äôun texte)\n",
    "- fill-mask\n",
    "- ner (named entity recognition ou reconnaissance d‚Äôentit√©s nomm√©es en fran√ßais)\n",
    "- question-answering\n",
    "- sentiment-analysis\n",
    "- summarization\n",
    "- text-generation\n",
    "- translation\n",
    "- zero-shot-classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TgmwK2d6OlFE"
   },
   "source": [
    "### 2.  Classification\n",
    "#### Z√©ro shot classification\n",
    "Classer des textes qui n‚Äôont pas √©t√© annot√©s. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "agGiUvz5Mho1"
   },
   "outputs": [],
   "source": [
    "classifier = pipeline(\"zero-shot-classification\")\n",
    "classifier(\n",
    "    \"C'est un cours sur la biblioth√®que Transformers\",\n",
    "    candidate_labels=[\"√©ducation\", \"politique\", \"affaires\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kujBeTwDO9_3"
   },
   "source": [
    "### 3.  G√©n√©ration de textes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "66Sc0NpBMho6"
   },
   "outputs": [],
   "source": [
    "generator = pipeline(\"text-generation\", model=\"asi/gpt-fr-cased-small\")\n",
    "generator(\"# Dans ce cours, nous vous enseignerons comment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# version en anglais\n",
    "enerator = pipeline(\"text-generation\")\n",
    "generator(\"In this course, we will teach you how to\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wb6QpQF6Mho8"
   },
   "outputs": [],
   "source": [
    "# model=\"distilgpt2\", ou un autre mod√®le pour les textes en anglais\n",
    "#model=\"asi/gpt-fr-cased-small\" pour des yextes en fran√ßais (exemple pris √† ttre indicatif)\n",
    "generator = pipeline(\"text-generation\",model=\"distilgpt2\" )\n",
    "generator(\n",
    "    \"In this course, we will teach you how to\",\n",
    "    max_length=30,\n",
    "    num_return_sequences=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0kU4aFbAPZ5a"
   },
   "source": [
    "### 4. Remplacement des mots masqu√©s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6UV_20PfMho_"
   },
   "outputs": [],
   "source": [
    "#exemple de mod√®les\n",
    "#model=\"camembert-base\" pour le francais\n",
    "unmasker = pipeline(\"fill-mask\")\n",
    "unmasker(\"This course will teach you all about <mask> models.\", top_k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cyZdM9VqMhpC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PvNljOY6Pao6"
   },
   "source": [
    "### 5. Reconnaissance d'entit√©s nomm√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_k7zh7FYMhpD"
   },
   "outputs": [],
   "source": [
    "#mod√®les\n",
    "# pour le rancais : model=\"Jean-Baptiste/camembert-ner\"\n",
    "ner = pipeline(\"ner\", grouped_entities=True)\n",
    "ner(\"My name is Sylvain and I work at Hugging Face in Brooklyn.\")\n",
    "#ner(\"Je m'appelle Sylvain et je travaille √† Hugging Face √† Brooklyn.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XZdeSFqnMhpF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZEIu6FbnQUTb"
   },
   "source": [
    "### 6. R√©ponse √† des questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZTX2bUsgMhpG"
   },
   "outputs": [],
   "source": [
    "#Mod√®le pour le fran√ßais\n",
    "#model=\"etalab-ia/camembert-base-squadFR-fquad-piaf\"\n",
    "question_answerer = pipeline(\"question-answering\")\n",
    "question_answerer(\n",
    "    question=\"Where do I work?\",\n",
    "    context=\"My name is Sylvain and I work at Hugging Face in Brooklyn\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cz8QMHu8MhpI"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Inspection du mod√®le utilis√© par d√©faut\n",
    "print(\"Mod√®le utilis√© :\", question_answerer.model.name_or_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XZQEgjAZQW7-"
   },
   "source": [
    "### 7. R√©sum√©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7m_mQN_jMhpJ"
   },
   "outputs": [],
   "source": [
    "summarizer = pipeline(\"summarization\", model=\"moussaKam/barthez-orangesum-abstract\")\n",
    "summarizer(\n",
    "    \"\"\"\n",
    "    L'Am√©rique a chang√© de fa√ßon spectaculaire au cours des derni√®res ann√©es. Non seulement le nombre de \n",
    "    dipl√¥m√©s dans les disciplines traditionnelles de l'ing√©nierie telles que le g√©nie m√©canique, civil, \n",
    "    l'√©lectricit√©, la chimie et l'a√©ronautique a diminu√©, mais dans la plupart \n",
    "    des grandes universit√©s am√©ricaines, les programmes d'√©tudes d'ing√©nierie se concentrent d√©sormais sur \n",
    "    et encouragent largement l'√©tude des sciences de l'ing√©nieur. Par cons√©quent, il y a \n",
    "    de moins en moins d'offres dans les sujets d'ing√©nierie traitant de l'infrastructure, \n",
    "    l'environnement et les questions connexes, et une plus grande concentration sur les sujets de haute \n",
    "    technologie, qui soutiennent en grande partie des d√©veloppements scientifiques de plus en plus \n",
    "    complexes. Si cette derni√®re est importante, elle ne doit pas se faire au d√©triment\n",
    "    de l'ing√©nierie plus traditionnelle.\n",
    "\n",
    "    Les √©conomies en d√©veloppement rapide telles que la Chine et l'Inde, ainsi que d'autres \n",
    "    pays industrialis√©s d'Europe et d'Asie, continuent d'encourager et de promouvoir\n",
    "    l'enseignement de l'ing√©nierie. La Chine et l'Inde, respectivement, dipl√¥ment \n",
    "    six et huit fois plus d'ing√©nieurs traditionnels que les √âtats-Unis. \n",
    "    Les autres pays industriels maintiennent au minimum leur production, tandis que l'Am√©rique \n",
    "    souffre d'une baisse de plus en plus importante du nombre de dipl√¥m√©s en ing√©nierie\n",
    "    et un manque d'ing√©nieurs bien form√©s.\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T9Ombhj_QrDc"
   },
   "source": [
    "### 9. Traduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VTIsplaDMhpM"
   },
   "outputs": [],
   "source": [
    "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-en-fr\")\n",
    "translator(\"This course is produced by Hugging Face.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Pipleone avec choix de la t√¢che et du mod√®le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "mon_pipeline = pipeline(\n",
    "    task=\"nom_de_la_t√¢che\",\n",
    "    model=\"nom_du_mod√®le\",\n",
    "    tokenizer=\"nom_du_tokenizer\",  # optionnel si identique au mod√®le\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\n",
    "    task=\"sentiment-analysis\",\n",
    "    model=\"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
    ")\n",
    "\n",
    "resultats = classifier(\"Ce film est excellent !\")\n",
    "print(resultats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| T√¢che (`task`)            | Description                                      |\n",
    "|--------------------------|--------------------------------------------------|\n",
    "| `sentiment-analysis`     | Classification de texte (binaire ou multi-classes) |\n",
    "| `text-classification`    | Synonyme g√©n√©rique de `sentiment-analysis`       |\n",
    "| `translation`            | Traduction automatique                           |\n",
    "| `summarization`          | R√©sum√© automatique de texte                      |\n",
    "| `question-answering`     | R√©ponse √† une question sur un contexte donn√©     |\n",
    "| `text-generation`        | G√©n√©ration de texte (type GPT)                   |\n",
    "| `fill-mask`              | Pr√©diction de mot masqu√© (type BERT)            |\n",
    "| `ner`                    | Reconnaissance d'entit√©s nomm√©es (Named Entity Recognition) |\n",
    "| `zero-shot-classification` | Classification sans fine-tuning sp√©cifique\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
