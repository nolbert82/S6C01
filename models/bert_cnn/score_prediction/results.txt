Frozen DistilBERT + CNN (score_label prediction)
BERT model: distilbert-base-uncased
Test rows: 10000
Data fraction: 0.1
Accuracy: 0.7153

Classification report:
              precision    recall  f1-score   support

           1     0.7699    0.8496    0.8078      1536
           2     0.5053    0.4046    0.4494       818
           3     0.5191    0.3399    0.4108       959
           4     0.5478    0.5299    0.5387      2055
           5     0.8149    0.8856    0.8487      4632

    accuracy                         0.7153     10000
   macro avg     0.6314    0.6019    0.6111     10000
weighted avg     0.6994    0.7153    0.7041     10000

