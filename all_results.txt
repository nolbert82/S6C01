
===== models\bert_cnn\polarity_prediction\results.txt =====
Frozen DistilBERT + CNN (polarity_label prediction)
BERT model: distilbert-base-uncased
Test rows: 10000
Data fraction: 0.1
Accuracy: 0.8900

Classification report:
              precision    recall  f1-score   support

          -1     0.8304    0.9235    0.8745      2354
           0     0.6039    0.2273    0.3303       959
           1     0.9269    0.9732    0.9495      6687

    accuracy                         0.8900     10000
   macro avg     0.7871    0.7080    0.7181     10000
weighted avg     0.8732    0.8900    0.8725     10000


===== models\bert_cnn\score_prediction\results.txt =====
Frozen DistilBERT + CNN (score_label prediction)
BERT model: distilbert-base-uncased
Test rows: 10000
Data fraction: 0.1
Accuracy: 0.7153

Classification report:
              precision    recall  f1-score   support

           1     0.7699    0.8496    0.8078      1536
           2     0.5053    0.4046    0.4494       818
           3     0.5191    0.3399    0.4108       959
           4     0.5478    0.5299    0.5387      2055
           5     0.8149    0.8856    0.8487      4632

    accuracy                         0.7153     10000
   macro avg     0.6314    0.6019    0.6111     10000
weighted avg     0.6994    0.7153    0.7041     10000


===== models\bert_finetune\polarity_prediction\results.txt =====
Fine-tuned DistilBERT (polarity_label prediction)
BERT model: distilbert-base-uncased
Test rows: 10000
Data fraction: 0.1
Accuracy: 0.8756

Classification report:
              precision    recall  f1-score   support

          -1     0.8341    0.8845    0.8586      2354
           0     0.4675    0.3379    0.3923       959
           1     0.9323    0.9496    0.9409      6687

    accuracy                         0.8756     10000
   macro avg     0.7447    0.7240    0.7306     10000
weighted avg     0.8646    0.8756    0.8689     10000


===== models\bert_finetune\score_prediction\results.txt =====
Fine-tuned DistilBERT (score_label prediction)
BERT model: distilbert-base-uncased
Test rows: 10000
Data fraction: 0.1
Accuracy: 0.6931

Classification report:
              precision    recall  f1-score   support

           1     0.7084    0.8919    0.7896      1536
           2     0.4689    0.2396    0.3172       818
           3     0.4828    0.2920    0.3639       959
           4     0.5277    0.4311    0.4746      2055
           5     0.7792    0.9065    0.8380      4632

    accuracy                         0.6931     10000
   macro avg     0.5934    0.5522    0.5566     10000
weighted avg     0.6628    0.6931    0.6678     10000


===== models\bert_gru\polarity_prediction\results.txt =====
Frozen DistilBERT + GRU (polarity_label prediction)
BERT model: distilbert-base-uncased
Test rows: 10000
Data fraction: 0.1
Accuracy: 0.8907

Classification report:
              precision    recall  f1-score   support

          -1     0.8219    0.9312    0.8731      2354
           0     0.6164    0.2513    0.3570       959
           1     0.9326    0.9681    0.9500      6687

    accuracy                         0.8907     10000
   macro avg     0.7903    0.7169    0.7267     10000
weighted avg     0.8762    0.8907    0.8751     10000


===== models\bert_gru\score_prediction\results.txt =====
Frozen DistilBERT + GRU (score_label prediction)
BERT model: distilbert-base-uncased
Test rows: 10000
Data fraction: 0.1
Accuracy: 0.7133

Classification report:
              precision    recall  f1-score   support

           1     0.7439    0.8796    0.8061      1536
           2     0.4918    0.4425    0.4659       818
           3     0.5875    0.3222    0.4162       959
           4     0.5349    0.5630    0.5486      2055
           5     0.8308    0.8536    0.8421      4632

    accuracy                         0.7133     10000
   macro avg     0.6378    0.6122    0.6158     10000
weighted avg     0.7056    0.7133    0.7046     10000


===== models\countvectorizer_logreg\polarity_prediction\results.txt =====
CountVectorizer + LogisticRegression (polarity_label prediction)
Shared vectorizer: text_representations\CountVectorizer\saved_model\count_vectorizer.pkl
Test rows: 100000
Accuracy: 0.8761

Classification report:
              precision    recall  f1-score   support

          -1     0.8507    0.8681    0.8593     23156
           0     0.5171    0.2821    0.3650      9796
           1     0.9115    0.9657    0.9378     67048

    accuracy                         0.8761    100000
   macro avg     0.7598    0.7053    0.7207    100000
weighted avg     0.8588    0.8761    0.8635    100000


===== models\countvectorizer_logreg\score_prediction\results.txt =====
CountVectorizer + LogisticRegression (score_label prediction)
Shared vectorizer: text_representations\CountVectorizer\saved_model\count_vectorizer.pkl
Total rows: 1000000
Train rows (first 90%): 900000
Test rows (last 10%): 100000
Accuracy: 0.6944

Classification report:
              precision    recall  f1-score   support

           1     0.7582    0.8492    0.8011     15447
           2     0.4545    0.3057    0.3656      7709
           3     0.4836    0.3723    0.4207      9796
           4     0.5427    0.4163    0.4712     20842
           5     0.7714    0.9013    0.8313     46206

    accuracy                         0.6944    100000
   macro avg     0.6021    0.5690    0.5780    100000
weighted avg     0.6691    0.6944    0.6755    100000


===== models\countvectorizer_mlp\polarity_prediction\results.txt =====
CountVectorizer + PyTorch MLP (polarity_label prediction)
Shared vectorizer: text_representations\CountVectorizer\saved_model\count_vectorizer.pkl
Test rows: 100000
Accuracy: 0.8802

Classification report:
              precision    recall  f1-score   support

          -1     0.8401    0.8915    0.8651     23156
           0     0.5486    0.2603    0.3531      9796
           1     0.9159    0.9669    0.9407     67048

    accuracy                         0.8802    100000
   macro avg     0.7682    0.7062    0.7196    100000
weighted avg     0.8624    0.8802    0.8656    100000


===== models\countvectorizer_mlp\score_prediction\results.txt =====
CountVectorizer + PyTorch MLP (score_label prediction)
Shared vectorizer: text_representations\CountVectorizer\saved_model\count_vectorizer.pkl
Test rows: 100000
Accuracy: 0.7015

Classification report:
              precision    recall  f1-score   support

           1     0.7504    0.8749    0.8079     15447
           2     0.4435    0.3456    0.3885      7709
           3     0.5103    0.3349    0.4044      9796
           4     0.5429    0.4699    0.5038     20842
           5     0.7938    0.8850    0.8369     46206

    accuracy                         0.7015    100000
   macro avg     0.6082    0.5821    0.5883    100000
weighted avg     0.6800    0.7015    0.6861    100000


===== models\countvectorizer_randomforest\polarity_prediction\results.txt =====
CountVectorizer + RandomForest (polarity_label prediction)
Shared vectorizer: text_representations\CountVectorizer\saved_model\count_vectorizer.pkl
Total rows: 1000000
Train rows (first 90%): 900000
Test rows (last 10%): 100000
Accuracy: 0.7095

Classification report:
              precision    recall  f1-score   support

          -1     0.9077    0.1770    0.2963     23156
           0     0.0000    0.0000    0.0000      9796
           1     0.7001    0.9970    0.8226     67048

    accuracy                         0.7095    100000
   macro avg     0.5359    0.3913    0.3729    100000
weighted avg     0.6796    0.7095    0.6201    100000


===== models\countvectorizer_randomforest\score_prediction\results.txt =====
CountVectorizer + RandomForest (score_label prediction)
Shared vectorizer: text_representations\CountVectorizer\saved_model\count_vectorizer.pkl
Total rows: 1000000
Train rows (first 90%): 900000
Test rows (last 10%): 100000
Accuracy: 0.5009

Classification report:
              precision    recall  f1-score   support

           1     0.7434    0.2543    0.3789     15447
           2     1.0000    0.0001    0.0003      7709
           3     1.0000    0.0001    0.0002      9796
           4     0.3445    0.0049    0.0097     20842
           5     0.4878    0.9968    0.6550     46206

    accuracy                         0.5009    100000
   macro avg     0.7151    0.2512    0.2088    100000
weighted avg     0.5871    0.5009    0.3633    100000


===== models\countvectorizer_svm\polarity_prediction\results.txt =====
CountVectorizer + SVM (polarity_label prediction)
Shared vectorizer: text_representations\CountVectorizer\saved_model\count_vectorizer.pkl
Test rows: 100000
Accuracy: 0.8402

Classification report:
              precision    recall  f1-score   support

          -1     0.8065    0.8089    0.8077     23156
           0     0.3741    0.3066    0.3370      9796
           1     0.9060    0.9290    0.9174     67048

    accuracy                         0.8402    100000
   macro avg     0.6955    0.6815    0.6874    100000
weighted avg     0.8309    0.8402    0.8351    100000


===== models\countvectorizer_svm\score_prediction\results.txt =====
CountVectorizer + SVM (score_label prediction)
Shared vectorizer: text_representations\CountVectorizer\saved_model\count_vectorizer.pkl
Test rows: 100000
Accuracy: 0.6148

Classification report:
              precision    recall  f1-score   support

           1     0.7288    0.7209    0.7248     15447
           2     0.3009    0.2657    0.2822      7709
           3     0.3343    0.3071    0.3201      9796
           4     0.4160    0.3837    0.3992     20842
           5     0.7504    0.8070    0.7777     46206

    accuracy                         0.6148    100000
   macro avg     0.5061    0.4969    0.5008    100000
weighted avg     0.6020    0.6148    0.6076    100000


===== models\tfidf_logreg\polarity_prediction\results.txt =====
TFIDF + LogisticRegression (polarity_label prediction)
Shared vectorizer: text_representations\TFIDF\saved_model\tfidf_vectorizer.pkl
Test rows: 100000
Accuracy: 0.8798

Classification report:
              precision    recall  f1-score   support

          -1     0.8512    0.8773    0.8640     23156
           0     0.5357    0.3068    0.3901      9796
           1     0.9168    0.9644    0.9400     67048

    accuracy                         0.8798    100000
   macro avg     0.7679    0.7161    0.7314    100000
weighted avg     0.8643    0.8798    0.8685    100000


===== models\tfidf_logreg\score_prediction\results.txt =====
TFIDF + LogisticRegression (score_label prediction)
Shared vectorizer: text_representations\TFIDF\saved_model\tfidf_vectorizer.pkl
Test rows: 100000
Accuracy: 0.6987

Classification report:
              precision    recall  f1-score   support

           1     0.7630    0.8560    0.8068     15447
           2     0.4637    0.3201    0.3788      7709
           3     0.4904    0.3819    0.4294      9796
           4     0.5407    0.4501    0.4912     20842
           5     0.7840    0.8886    0.8330     46206

    accuracy                         0.6987    100000
   macro avg     0.6084    0.5793    0.5879    100000
weighted avg     0.6766    0.6987    0.6832    100000


===== models\tfidf_mlp\polarity_prediction\results.txt =====
TFIDF + PyTorch MLP (polarity_label prediction)
Shared vectorizer: text_representations\TFIDF\saved_model\tfidf_vectorizer.pkl
Test rows: 100000
Accuracy: 0.8820

Classification report:
              precision    recall  f1-score   support

          -1     0.8414    0.8935    0.8666     23156
           0     0.5399    0.3029    0.3881      9796
           1     0.9232    0.9627    0.9425     67048

    accuracy                         0.8820    100000
   macro avg     0.7682    0.7197    0.7324    100000
weighted avg     0.8667    0.8820    0.8707    100000


===== models\tfidf_mlp\score_prediction\results.txt =====
TFIDF + PyTorch MLP (score_label prediction)
Shared vectorizer: text_representations\TFIDF\saved_model\tfidf_vectorizer.pkl
Test rows: 100000
Accuracy: 0.7036

Classification report:
              precision    recall  f1-score   support

           1     0.7667    0.8583    0.8099     15447
           2     0.4502    0.3973    0.4221      7709
           3     0.5133    0.3485    0.4152      9796
           4     0.5382    0.5109    0.5242     20842
           5     0.8082    0.8653    0.8357     46206

    accuracy                         0.7036    100000
   macro avg     0.6153    0.5961    0.6014    100000
weighted avg     0.6890    0.7036    0.6937    100000


===== models\tfidf_randomforest\polarity_prediction\results.txt =====
TFIDF + RandomForest (polarity_label prediction)
Shared vectorizer: text_representations\TFIDF\saved_model\tfidf_vectorizer.pkl
Test rows: 100000
Accuracy: 0.7068

Classification report:
              precision    recall  f1-score   support

          -1     0.9121    0.1639    0.2779     23156
           0     0.0000    0.0000    0.0000      9796
           1     0.6979    0.9975    0.8212     67048

    accuracy                         0.7068    100000
   macro avg     0.5366    0.3872    0.3664    100000
weighted avg     0.6791    0.7068    0.6150    100000


===== models\tfidf_randomforest\score_prediction\results.txt =====
TFIDF + RandomForest (score_label prediction)
Shared vectorizer: text_representations\TFIDF\saved_model\tfidf_vectorizer.pkl
Test rows: 100000
Accuracy: 0.4989

Classification report:
              precision    recall  f1-score   support

           1     0.7438    0.2424    0.3657     15447
           2     0.0000    0.0000    0.0000      7709
           3     0.0000    0.0000    0.0000      9796
           4     0.3538    0.0033    0.0066     20842
           5     0.4862    0.9971    0.6536     46206

    accuracy                         0.4989    100000
   macro avg     0.3168    0.2486    0.2052    100000
weighted avg     0.4133    0.4989    0.3599    100000


===== models\tfidf_svm\polarity_prediction\results.txt =====
TFIDF + SVM (polarity_label prediction)
Shared vectorizer: text_representations\TFIDF\saved_model\tfidf_vectorizer.pkl
Test rows: 100000
Accuracy: 0.8689

Classification report:
              precision    recall  f1-score   support

          -1     0.8289    0.8633    0.8457     23156
           0     0.5118    0.2507    0.3366      9796
           1     0.9065    0.9611    0.9330     67048

    accuracy                         0.8689    100000
   macro avg     0.7491    0.6917    0.7051    100000
weighted avg     0.8499    0.8689    0.8544    100000


===== models\tfidf_svm\score_prediction\results.txt =====
TFIDF + SVM (score_label prediction)
Shared vectorizer: text_representations\TFIDF\saved_model\tfidf_vectorizer.pkl
Test rows: 100000
Accuracy: 0.6627

Classification report:
              precision    recall  f1-score   support

           1     0.7334    0.8233    0.7758     15447
           2     0.3873    0.2401    0.2964      7709
           3     0.4236    0.3037    0.3538      9796
           4     0.4790    0.3975    0.4345     20842
           5     0.7550    0.8752    0.8107     46206

    accuracy                         0.6627    100000
   macro avg     0.5557    0.5280    0.5342    100000
weighted avg     0.6333    0.6627    0.6425    100000


